# Multimodal AI (Series)

In this series, I explore recent developments in multimodal AI systems. Each topic is accompanied by a YouTube video and Medium blog post. For those with code examples, the notebooks are freely available in this repo.

**Topics**
- Multimodal Models (LLMs): [Video](https://youtu.be/Ot2c5MKN_-w) | [Blog](https://towardsdatascience.com/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3) | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/1-mm-llms)
- Mulitmodal Embeddings: [Video](https://youtu.be/YOvxh_ma5qE) | [Blog](https://towardsdatascience.com/multimodal-embeddings-an-introduction-5dc36975966f) | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/2-mm-embeddings)
- Mulitmodal RAG: Video | Blog | [Code](https://github.com/ShawhinT/YouTube-Blog/tree/main/multimodal-ai/3-multimodal-rag)

### Supplemental Materials

ðŸŽ¥ [YouTube Playlist](https://www.youtube.com/playlist?list=PLz-ep5RbHosXxOAPMThZM1rMec8sV7FcX) <br>
ðŸ“° [Medium Reading List](https://shawhin.medium.com/list/multimodal-ai-fe9521d0e77a)
<br><br>
