{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32448200-82ae-41e2-b353-a5bb96a3e9fa",
   "metadata": {},
   "source": [
    "# Create Training Dataset for Embedding Fine-tuning\n",
    "\n",
    "Code authored by: Shaw Talebi\n",
    "\n",
    "Video link (coming soon!) <br>\n",
    "Blog link (coming soon!) <br>\n",
    "Dataset (coming soon!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c387ad9-14db-46eb-8671-94d2e3f2eb88",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193d45ec-ce81-4828-95d4-28fa6fba139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from datasets import DatasetDict, Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from functions import clean_html, remove_irrelevant_sections, extract_qualifications_from_html, remove_eoe_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b80c77-27ca-4950-8317-c0142f2e7706",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e12730e-e2a2-4a88-a72e-981a2dfb2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract JDs\n",
    "df_jobs = pd.read_csv(\"data/job_data.csv\")\n",
    "df_jobs = df_jobs.drop_duplicates()\n",
    "\n",
    "# remove HTML tags from job_descriptions\n",
    "df_jobs['job_description_cleaned'] = df_jobs['job_description'].apply(clean_html)\n",
    "# only keep text relevant to job qualifications\n",
    "df_jobs['job_description_cleaned'] = df_jobs['job_description_cleaned'].apply(remove_irrelevant_sections)\n",
    "df_jobs['job_description_cleaned'] = df_jobs['job_description_cleaned'].apply(extract_qualifications_from_html)\n",
    "df_jobs['job_description_cleaned'] = df_jobs['job_description_cleaned'].apply(remove_eoe_notes)\n",
    "\n",
    "# store job descriptions in a list\n",
    "job_description_list = df_jobs['job_description_cleaned'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b99799d-db3c-4007-9878-8ae116186430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract synthetic queries and store in list\n",
    "file_path = 'data/output.jsonl'\n",
    "query_list = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        query = json.loads(line)['response']['body']['choices'][0]['message']['content'].replace('\"', '')\n",
    "        query_list.append(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71664088-bbcf-46d8-a58e-2f02b2c63efa",
   "metadata": {},
   "source": [
    "### create positive pairs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8faa3f5-acda-4685-bb4f-1d47c96281bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict with queries and JDs\n",
    "df = pd.DataFrame({\"query\" : query_list, \"job_description_pos\" : job_description_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7b999e-67f5-41c4-89f3-b97cc5f1835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1087, 2)\n",
      "Unique JDs: (828, 2)\n",
      "Unique queries: (826, 2)\n"
     ]
    }
   ],
   "source": [
    "# drop duplicates\n",
    "print(\"Original shape:\", df.shape)\n",
    "df = df.drop_duplicates(subset=['job_description_pos'])\n",
    "print(\"Unique JDs:\", df.shape)\n",
    "df = df.drop_duplicates(subset=['query'])\n",
    "print(\"Unique queries:\",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d654eb-6972-410c-994f-7c9f9d6f5cce",
   "metadata": {},
   "source": [
    "### create negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedfc469-fb7e-47f5-8ec2-c87a7896daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec5cf0b-bc5d-4ca8-be62-a58b0bbaa6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(826, 768)\n",
      "CPU times: user 30.4 s, sys: 10.1 s, total: 40.4 s\n",
      "Wall time: 54.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encode all job descriptions\n",
    "job_embeddings = model.encode(df['job_description_pos'].to_list())\n",
    "print(job_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e161aed6-0aa5-4c52-8c52-c4956fe10f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([826, 826])\n"
     ]
    }
   ],
   "source": [
    "# compute similarities\n",
    "similarities = model.similarity(job_embeddings, job_embeddings)\n",
    "print(similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed79d19a-d75b-45d6-bb48-ad00cbd69c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match least JDs least similar to positive match as the negative match\n",
    "similarities_argsorted = np.argsort(similarities.numpy(), axis=1)\n",
    "negative_pair_index_list = []\n",
    "\n",
    "for i in range(len(similarities)):\n",
    "\n",
    "    # Start with the smallest similarity index for the current row\n",
    "    j = 0\n",
    "    index = int(similarities_argsorted[i][j])\n",
    "\n",
    "    # Ensure the index is unique\n",
    "    while index in negative_pair_index_list:\n",
    "        j += 1  # Move to the next smallest index\n",
    "        index = int(similarities_argsorted[i][j])  # Fetch next smallest index\n",
    "\n",
    "    negative_pair_index_list.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1828098c-a0b5-4fef-a2d5-50f284d866f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add negative pairs to df\n",
    "df['job_description_neg'] = df['job_description_pos'].iloc[negative_pair_index_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22900620-acd2-4dde-b7d6-cdcf89c80643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>job_description_pos</th>\n",
       "      <th>job_description_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Staff Data Scientist specialized in generative...</td>\n",
       "      <td>experience) in Operations Research, Statistics...</td>\n",
       "      <td>At Broadridge, we've built a culture where the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compliance Testing, Generative AI, Prompt Engi...</td>\n",
       "      <td>skills to translate the complexity of your wor...</td>\n",
       "      <td>experience, and/or performance. Base pay is ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>federal AI strategy consulting, natural langua...</td>\n",
       "      <td>skills and strategic ideas to improve mission ...</td>\n",
       "      <td>qualifications of the individual and do not di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generative AI techniques, data visualization t...</td>\n",
       "      <td>experienced in applying advanced statistical m...</td>\n",
       "      <td>skills and deserves to experience an epic win....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist, statistical analysis, b...</td>\n",
       "      <td>ExperienceProduct Allowance so you can kick ba...</td>\n",
       "      <td>requirements, specifications, and constraints,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Staff Data Scientist specialized in generative...   \n",
       "1  Compliance Testing, Generative AI, Prompt Engi...   \n",
       "2  federal AI strategy consulting, natural langua...   \n",
       "3  generative AI techniques, data visualization t...   \n",
       "4  Senior Data Scientist, statistical analysis, b...   \n",
       "\n",
       "                                 job_description_pos  \\\n",
       "0  experience) in Operations Research, Statistics...   \n",
       "1  skills to translate the complexity of your wor...   \n",
       "2  skills and strategic ideas to improve mission ...   \n",
       "3  experienced in applying advanced statistical m...   \n",
       "4  ExperienceProduct Allowance so you can kick ba...   \n",
       "\n",
       "                                 job_description_neg  \n",
       "0  At Broadridge, we've built a culture where the...  \n",
       "1  experience, and/or performance. Base pay is ju...  \n",
       "2  qualifications of the individual and do not di...  \n",
       "3  skills and deserves to experience an epic win....  \n",
       "4  requirements, specifications, and constraints,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857eae3-19e1-4e75-af14-62cbd9fb0dd0",
   "metadata": {},
   "source": [
    "### train-eval-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992598e2-fd59-4fb7-b548-86aa6bd3a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split into train, validation, and test sets (e.g., 80% train, 10% validation, 10% test)\n",
    "train_frac = 0.8\n",
    "valid_frac = 0.1\n",
    "test_frac = 0.1\n",
    "\n",
    "# define train and validation size\n",
    "train_size = int(train_frac * len(df))\n",
    "valid_size = int(valid_frac * len(df))\n",
    "\n",
    "# create train, validation, and test datasets\n",
    "df_train = df[:train_size]\n",
    "df_valid = df[train_size:train_size + valid_size]\n",
    "df_test = df[train_size + valid_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8afa6e-cf80-42a7-9a5c-9d611f057211",
   "metadata": {},
   "source": [
    "### upload to hugging face hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f342bad7-6221-4955-acb5-189efc3b18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas DataFrames back to Hugging Face Datasets\n",
    "train_ds = Dataset.from_pandas(df_train)\n",
    "valid_ds = Dataset.from_pandas(df_valid)\n",
    "test_ds = Dataset.from_pandas(df_test)\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': valid_ds,\n",
    "    'test': test_ds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4be4fbc-105f-41ab-b10d-6dfa88f9c519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['query', 'job_description_pos', 'job_description_neg'],\n",
       "        num_rows: 660\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['query', 'job_description_pos', 'job_description_neg'],\n",
       "        num_rows: 82\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['query', 'job_description_pos', 'job_description_neg'],\n",
       "        num_rows: 84\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e5a6e0-ec9f-4659-979a-d9f5c01475e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8446f5419ac407db02cef5bf1b721e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66486ea95ca24b67b56d984755828549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c48f973a15e4509809195997d2b1828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85382ae1dc2a4666a227ca9528fcefd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62535c3168234778a458fffe1f8f9ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037eae7ddb03481393bafece70a39dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/shawhin/ai-job-embedding-finetuning/commit/e5013221c56a6cf5bf8a65a46dbed8520dbcfb7d', commit_message='Upload dataset', commit_description='', oid='e5013221c56a6cf5bf8a65a46dbed8520dbcfb7d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/shawhin/ai-job-embedding-finetuning', endpoint='https://huggingface.co', repo_type='dataset', repo_id='shawhin/ai-job-embedding-finetuning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push data to hub\n",
    "dataset_dict.push_to_hub(\"shawhin/ai-job-embedding-finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49521b7-fa5e-426d-9056-9ed8206abe28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
